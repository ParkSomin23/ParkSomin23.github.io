---
title: "Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis"
date: 2022-02-07 23:00
category: "논문-리뷰"
tag: [MIL, Text]
published: true

toc: true
toc_sticky: true
use_math: true
---

> 논문: [Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis](https://transacl.org/ojs/index.php/tacl/article/view/1225/277)  

# 1. What is MIL? 
<p>
<img src = "../assets/images/MIL/img_00002.png" width="100%">
</p>

- MIL: multiple instance learning
- 레이블이 instance들고 구성된 bag에 연관되어 있으나, instance에 레이블이 없는 경우의 문제를 해결하기 위해 고안됨
- 각 키들은 instance이고, key 3개로 구성되어 있는 경우가 bag<br>
  각 bag로 방문을 열 수 있는지 없는지에 대한 레이블은 제공되나, 어떤 키가 방문 열쇠인지 레이블은 제공되지 않을 때, 핵심 key를 찾는 방법이 MIL
- [이미지 출처](https://velog.io/@d9249/Accounting-for-Dependencies-in-Deep-Learning-Based-Multiple-Instance-Learning-for-Whole-Slide-Imaging)
<br><br>

<p>
<img src = "../assets/images/MIL/img_00003.png" width="100%">
</p>

- 식당 리뷰를 보고 별점을 예측하는 문제에 적용해보면...
- bag는 문서 전체, 각 문장들은 instance
- 각 문장에 해당하는 별점을 구하고, 이를 종합하여 최종 별점 판단 진행
<br><br>

<p>
<img src = "../assets/images/MIL/img_00006.png" width="100%">
</p>

- 위 논문은 MIL 방식을 활용하여 sentiment 분석 진행
- Contribution
    1. 각 문장에 대한 레이블이 아닌 전체 문서 레이블만을 가지고, 이를 구성한 문장들의 sentiment의 극성(polarity) 판단하는 새로운 MIL 방법 제시
    2. SPOT 데이터 셋 생성: Segment-level POlariTy annotation(for sentences and EDUs)을 제공하는 publicly available dataset 
    3. 리뷰에서 segment sentiment을 찾고 유용한 정보를 찾는데 neural multiple instance learning이 다른 neural architecture나 다른 baselines보다 더 나은 성능을 보이는 것을 찾음
<br><br>

# 2. Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis
<p>
<img src = "../assets/images/MIL/img_00007.png" width="100%">
</p>

- 왼쪽은 제안된 network 구조, 오른쪽은 본 논문에서 사용한 word matrices에 대한 [논문](https://arxiv.org/abs/1408.5882) 
- 단어 embedding
    - publicly available word2vec vectors (100 billion words from Google News) 
    - 각 단어는 300 차원 벡터로 구성
    - continuous bag-of-words architecture로 학습됨 
    - 없는 단어들은 random하게 initalize
- 문장 embedding을 위해, 여러 크기의 window filter를 사용 (빨간 상자 & 노란 상자)
- 각 filter를 통해 나온 결과의 최대값을 pooling
    - 가장 중요한 정보를 찾기 위해서
    - one feature is extracted from one filter
    - 다양한 길이의 문장을 같은 크기로 embedding 가능 (=filter 개수)
<br><br>

<p>
<img src = "../assets/images/MIL/img_00008.png" width="100%">
</p>

- **segment encoding** 
    - word matrices를 CNN 구조를 활용하여 segment를 encoding하여 $v_i$ 생성
- **segment classification**
    - 각 $v_i$들은 classifier learnable 파라미터 $W_c$와 $b_c$를 사용하여 mapping하고 softmax을 지나 분포 $p_i$ 생성
        $$p_i = softmax(W_c v_i + b_c)$$
- **document classification**
    - 단순하게 segment distribution의 평균을 사용하지 않고 segment attention mechanism 사용 
    - bidirectional GRU에 segment distribution $p_i$을 넣어 $h_i$ output 생성
    - 생성된 $h_i$ 값은 learnable 파라미터인 $W_a$와 $b_a$를 통해 mapping하고, tanh 활성화 함수를 거쳐 $h_i'$가 -1 ~ 1 사이의 점수를 갖도록 함
    - 각 segment의 attention score는 아래 수식으로 구함
        $$a_i = \frac{exp(h_i' h_a)}{\sum_i exp(h_i'^T h_a)}$$ 
        $h_a$: random initalize하여 사용하는 learnable vector로, sentiment-heavy segment들을 인식하는 trained key로 볼 수 있음
    - 최종 document-level distribution는 segment distribution의 weighted sum으로 구함
        $$p_d^{(c)} = \sum_i a_ip_i^{(c)}, \; c\in[1, C]$$
        C: class 개수 
- **loss function**
    - negative log likelihood of the document-level prediction
    $$L = -\sum_d log\ p_d^{(y_d)}$$
<br>

<p>
<img src = "../assets/images/MIL/img_00009.png" width="100%">
</p>

- inference 단계에서 opinion extraction (selecting highly positive and negative snippets)이 가능

- **polarity scoring**
    - 각 segment의 class probability distribution $p_i$를 polarity score로 변환
    - real-valued class weight vector $w = \langle w^{(1)}, \cdots, w^{(C)}\ \vert \ w^{(c)} \in [-1,1]\rangle$ 생성 <br>
    균등하게 weight 분배, $w^{(c+1)}- w^{(c)}=\frac{2}{C-1}\qquad$ (ex) C=5일 때, $w=\langle -1,\ -0.5,\ 0,\ 0.5,\ 1\rangle$
    - polarity score는 $p_i$와 $w$의 dot product로 계산
        $$\text{polarity}(s_i)=\sum_c p_i^{(c)} w^{(c)} \in [-1,\ 1]$$

- **gated polarity**
    - 중요한 sentiment 정보를 담고 있는지 없는지 구분하는 방법
        $$\text{gated-polarity}(s_i) = a_i\ \cdot\ \text{polarity}(s_i) $$ 
        $a_i$: i번 째 segment의 attention score 값

- **Figure 3**
    - 1번 째와 2번 째 segment는 부정적인 sentiment이며, 음수 점수를 받음. 3번 째 segment는 양수 점수받음
    - 1번 째와 2번 째 segment가 동일한 2번 째 class로 예측했으나, 2번 째 segment는 모든 class의 분포가 더 균등하게 분포하고 있기에 0 (neutral)에 가까운 값 갖음
<br><br>

<p>
<img src = "../assets/images/MIL/img_00010.png" width="100%">
</p>

- 좌측 이미지: Distribution of segment-level labels per document-level class on our the SPOT datasets
- 우측 이미지: HierNet 논문들과 비교
    - HierNet에서는 neutral class에서 polarity가 전체 클래스에 골고루 분포하는 문제 발생
    - MILNET은 neutral 문장의 점수가 0 근처에 분포하여 HeirNet 문제 해결<br>
    이는 attention gating 방식에 의한 결과
<br><br>

# 3. SER Related 논문
<p>
<img src = "../assets/images/MIL/img_00004.png" width="100%">
</p>

<p>
<img src = "../assets/images/MIL/img_00005.png" width="100%">
</p>


