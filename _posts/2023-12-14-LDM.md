---
title: "High-Resolution Image Synthesis with Latent Diffusion Models(Latent Diffusion)"
date: 2023-12-14 15:00
category: "논문-리뷰"
tag: [Vision, Diffusion]
published: false

toc: true
toc_sticky: true
use_math: true
---

> 논문: [High-Resolution Image Synthesis with Latent Diffusion Models](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)

<span style='background-color:#fff5b1'></span>

# Abstract
- 기존 diffusion model들은 input image 크기를 유지하기에 연산량이 많은 문제가 존재 (pixel space)<br>
$\rightarrow$ 이를 해결하기 위해 pretrained autoencoder의 latent space에서 diffusion 진행
- cross-attention layer를 사용<br> 
$\rightarrow$ text나 bounding boxes와 같은 conditional generator로 사용 가능& convolution 방식으로 고해상도 이미지 생성 가능

# 1. Introduction
- likelihood-based model 장점<br>
1\) mode-collapse 없음<br>
2\) GANs보다 안정적인 학습<br>
3\) parameter sharing으로 Autoregressive(AR) model처럼 수 십억 parameter들이 필요 없음

- likelihood-based model 단점<br>
1\) data의 미세한(imperceptible) 묘사를 위해 과도한 양의 용량(컴퓨팅 리소스)을 소비<br>
2\) 학습 및 sampling 시에 많은 연산과 시간 필요
<br><br>

-  본 논문에서 latent space를 사용하게 된 이유
    <p align='center'>
    <img src="../assets/images/LDM/img_01.jpeg" width="60%">
    </p>

    - pixel space에서 학습한 diffusion model의 rate-distortion trade-off<br>
        rate가 1.5 이상 ~ 0.5까지에서의 이미지의 차이를 사람이 잘 느끼지 못 함<br>
        즉, digital image의 대부분의 bits가 인지할 수 없는(imperceptible) details를 나타냄을 의미함
    
    - likelihood-base model들은 애략 2개의 stage로 나눠질 수 있음<br>
        1\) Perceptual (인지적인) compression stage: high-frequency detail은 지우지만, 작은 의미적인(semantical) 변화 학습<br>
        2\) Semantic (의미적인) compression stage: 실제 generative model이 데이터의 sematic & conceptual 요소 학습
            
    - 제안된 논문의 목표는 고해상도 이미지 생성을 위한 diffusion model를 학습시킬, <span style='background-color:#fff5b1'> 인지적인 차이는 없지만 (perceptually equivalent)연산적으로 더 적합한 space를 찾는 것</span>

- 제안된 Latent Diffusion Models
    - 먼저 auto-encoder 학습하여, data space에서 인지적으로는 동일하지만 더 작은 차원으로 효율적인 representational space를 찾음<br>
    diffusion model이 latent space에서 학습되므로, 공간적 차원과 관련하여 더 나은 scaling 특징을 나타냄<br><br>
    그렇기에 이전 방식과 다르게, 과도한 공간적 압축(spatial compression)에 의존하지 않아도 됨<br>
    또한, 한 개의 network pass만으로도 latent space에서 효율적인 이미지 생성이 가능해짐

    - $\Rightarrow$ <span style='background-color:#fff5b1'>**Latent Diffusion Models (LDMs)**</span>
    
    - 제안된 방법의 장점<br>
        보편적인 autoencoding stage를 단 한 번만 학습 가능해서, 다양한 diffusion model 학습에 재활용하거나 완전히 다른 task에 사용할 수 있음<br>

        $\Rightarrow$ diffusion model의 UNet에 transformer를 연결하는 구조 제안하여, 임의의 종류에 대한 token-based conditioning 방법이 가능하게 함

## Contributions
1. 이전의 순수한 transformer-based 방법과 달리, 더 높은 차원 데이터에 대해 확장이 용의<br>
    a\) 더 충실하고 상세한 reconstruction이 가능하게 하는 압축된 level에서 작업 가능<br>
    b\) 고해상도인 megapixel 이미지 생성에 효울적으로 적용 가능 

2. 다양한 task와 dataset에 대해 경쟁력 있는 성능을 보여주며, 연산량을 확연하게 낮춤<br>
    a\) unconditional image synthesis, inpainting, stochastic super-resolution<br>
    b\) pixel-based diffusion에 비해 inference cost도 확연하게 감소됨

3. reconstruction과 생성 능력을 위한 섬세한 weighting이 필요하지 않음<br>
    a\) 그 이유는 encoder/decoder 구조와 score-based prior를 동시에 학습하지 않아도 되기 때문
    b\) 굉장히 충실한 reconstruction을 보증하고, latent space에 대한 regularization이 매우 적게 요구 됨

4. convolutional 방식에 대해 적용될 수 있고, 더 크고 안정된 이미지 생성 가능<br>
    a\)super-resolution, inpainting, semantic synthesis과 같은 조밀한 conditioned task들에 적용 가능<br>
    b\) $~ 1024^2$ px 까지 확장 가능

5. cross-attention에 기반으로 일반화된 목적을 위한 conditioning 방법을 디자인하여, multi-modal 학습 가능<br>
    class-conditional, text-to-image, layout-to-image

6. released pretrained latent diffusion and autoencoding models<br>
    https://github.com/CompVis/latent-diffusion 
<br><br>

# 2. Related Work
## Generative Models for Image Synthesis
- **GAN (Generative Adversarial Networks)**<br>
  장점: 효율적이며 좋은 인지적 성능(perceptual quality)의 고해상도 이미지 sampling 가능<br>
  단점: optimize 어려움, 전체적인 데이터 분포 포착하기 어려움

- **likelihood-based**<br>
    optimization이 더 잘 되어, 밀도 추정이 훨씬 더 잘 됨

- **VAE (Variational autoencoders)** & **flow-based**<br>
    장점: 더 효율적인 고해상도 이미지 생성 가능
    단점: GAN보다 성능이 낮음

- **ARM (autoregressive models)**<br>
    장점: 밀도 추정에서 엄청 좋은 성능을 보임<br>
    단점: 계산적으로 까다로운 구조와 순차적인 sampling 과정으로 인해 저해상도 이미지만 생성 가능<br>
        이미지를 pixel 기반 representation으로 나타내면, 이에 거의 인지할 수 없는 고주파의 세부사항이 담겨 있음<br>
        이를 maximum-likelihood로 학습하면, modeling 할 때 불균형한 양의 용량을 소비하기에 학습 시간이 길어짐<br>

    $\Rightarrow$ 고해상도 이미지를 생성하기 위해 **two-stage** 접근 방법들이, ARM 모델로 raw pixel을 latent image space로 압축하는 방법들을 제안

## Diffusion Probabilistic Models
- 밀도 추정이나 sample 품질에서 SOTA (state-of-the-art) 달성<br>
    neural backbone이 UNet과 같은 구조로 구현될 때, image-like data의 [inductive bias (보지 못한 데이터에 대해서도 귀납적 추론이 가능하도록 하는 알고리즘이 가지고 있는 가정의 집합)](https://re-code-cord.tistory.com/entry/Inductive-Bias란-무엇일까)에 대한 자연스러운 적합성에서 비롯됨 
- 학습 시에 [reweighted objective](https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf)가 사용되었을 때의 생성 능력이 뛰어났음<br>
    diffusion model은 손실이 있는 압축기(lossy compressor)에 해당됨 (이미지 품질과 압축 능력의 trade-off)
- pixel space에서 평가하고 모델을 최적화하면, inference speed가 느리고 학습 비용도 많이 듦<br>
    inference speed를 보완하기 위해서 advanced sampling 방법이나 hierarchical 접근 방식을 사용할 수 있음<br>
    하지만, 고해상도 이미지 데이터는 항상 gradients 연산이 많이 필요함<br>

    $\Rightarrow$ <span style='background-color:#fff5b1'>제안된 방법에서는 LDMs 방식으로 위 두 문제 해결, **저차원의 압축된 latent space에서 수행**</span>

## Two-Stage Image Synthesis
- **VQ-VAEs**<br>
    autoregressive model를 사용하여, 이산화된(discretized) latent space의 표현상의 사전 확률(prior)를 학습 진행<br>
    text-to-image로 확장 (이산화된 이미지와 텍스트 representations의 **joint distribution**을 학습)<br>
    다양한 도메인의 latent spaces 사이의 일반적인 전달을 위해, **conditionally invertible network**까지 제안됨 

- **VQGANs**<br>
    첫 stage를 adversarial과 perceptual objective로 학습하여, autoregressive transformers가 더 큰 이미지로 확장될 수 있게 함<br>
    하지만, 실행 가능한 ARM 학습을 위해 압축률을 높게 하면 막대한 학습 가능한 parameters들이 필요함<br>
    즉, **전체적인 성능이 제한**되거나 압축이 적게 되어 **연산량이 많아**지게 되는 문제 발생<br>

    $\Rightarrow$ 위의 상층 관계를 해결하기 위해 LDAs 제안

    **convolution backbone**이 있기 떄문에, 더 큰 차원의 latent space로 완만하게 크기를 키울 수 있음<br>
    따라서, generative diffusion model까지 너무 많은 인지적인 압축 정보를 주지 않지만 강력한 첫 번째 stage를 학습하면서도, 충실한 reconstruction이 가능하도록 <span style='background-color:#fff5b1'>압축 정도를 자유롭게 정할 수 있음</span><br>
    
    
    - [ ] section 4 읽고 다시 정리!!
    score-based prior로 encoder/decoder를 함께 학습하면는 방법들이 이전애도 있었지만, reconsturction과 생성 능력 사이의 가중치를 조절하는 것이 어렵다는 한계가 있음<br>
    [While approaches to jointly learn an encoding/decoding model together with a score-based prior exist [90], they still require a difficult weighting between reconstruction and generative capabil- ities [11] and are outperformed by our approach (Sec. 4).]
<br><br>

# 3. Method
- compression과 denterative learning phase의 **분리**<br>
    autoencoding model이 image space와 동등한 인지적 space를 배워, 연산량을 확연하게 줄여줌
- 장점<br>
    1. 더 낮은 차원에서 sampling되기 때문에, 연산이 훨씬 효율적임
    2. UNet에서 상속된 diffusion model의 inductive bias를 사용하여, 공간적 구조를 갖는 데이터에 대해 효과적으로 사용 가능<br>
    $\rightarrow$ 공격적이며(aggressive) 품질을 낮추는 압축 level의 필요성을 경감시킴
    3. 전반적 목적(general-purpose) 압축 모델 생성 가능<br> 
        생성된 latent space를 다양한 생성 model 학습에 사용하거나, 압축 모겔을 다른 downstream application에 사용 가능

## 3.1. Perceptual Image Compression
- 이전 방식 [23](https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf)을 기반이며, perceptual loss와 patch-based adversarial objective으로 학습된 autoencoder를 포함함<br>
    $\Rightarrow$ 국소성의 실재성(local realism, 국소적으로만 영향을 미치는)을 강화하여 reconstruction이 image manifold에 국한되도록 보장하고, $L_1$이나 $L_2$와 같이, pixel space에만 영향 받는 손실 함수들에 의한 **bluriness 해소**

- image: $x\in \mathbb{R}^{H\times W \times 3}$<br>
    $\text{encoder } \mathcal{E}(x) \rightarrow \text{latent representation } z \in \mathbb{R}^{h\times w\times c}$<br>
    $\text{decoder } \mathcal{D}(z) \rightarrow \text{reconstructed image } \tilde{x}$<br>
    encoder downsampling factor $f$: $f = H/h = W/w$

- 임의의 높은 분산(high-variance) latent space를 피하기 위해 **2가지 regularizations을 사용**한 실험 진행
    1. KL-reg.: VAE처럼 학습된 latent의 표준 정규화에 약간의 KL-penalty 부과
    2. VQ-reg.: VQGAN과 비슷하지만 decoder에 vector quantization layer 사용
    
- 뒤에 오는 diffusion model에서 학습된 latent space $z=\mathcal{E}(x)$가 **2차원 구조**에서 작동되므로, 상대적으로 온화한(mild) 압축률을 사용할 수 있고 좋은 reconstruction 성능 달성 가능<br>
    1차원을 사용하는 이전 방식과 다르게, $x$의 특징을 더 잘 보존함

## 3.2. Latent Diffusion Models
### Diffusion Models
- 정규 분포 변수를 점진적으로 denoising하여 data distribution $p(x)$를 학습하는 probabilistic models로, 길이가 $T$인 고정된 Markov Chain의 역과정을 학습하는 것과 같음<br>
    image synthsis에서는 주로 $p(x)$의 가중치를 변경한 variational lower bound을 사용 (denosing score-matching)
- 동일한 가중치를 가진 연속적인 autoencoders $\epsilon_\theta(x_t,t)\ (t=1, \cdots, T)$들을 denoising하는 과정으로 해석됨<br>
    즉, $x_t$ (noisy version of the input $x$)에 대한 **denoised variant를 예측**하도록 학습

    $$L_{DM} = \mathbb{E}_{x, \epsilon \sim \mathcal{N}(0,1), t}[\ \Vert \epsilon - \epsilon_\theta(x_t,t) \Vert^2_2\ ]$$

    - with $t$ uniformly sampled from $\{1, \cdots, T\}$
    - <details>
        <summary>손실 함수 유도 과정: Appendix A</summary>
        <div markdown="1">

        - 관련된 자세한 내용은 "Variational Diffusion Models" 읽고 공부하고 더 깊게 정리해야함 <span style="color:gray">(!! 좀 더 깊게 공부할 필요 있음 !!)</span>

        - diffusion model은 sequence $(\alpha_t)^T_{t=1}$와 $(\sigma_t)^T_{t=1}$ 로 구성된 signal-to-noise ratio $SNR(t)= \frac{\alpha_t^2}{\sigma_t^2}$ 로 볼 수 있음<br>
        $\alpha_t$는 신호, $\sigma_t$는 noise의 전력에 해당하여, 상대적인 신호 전력 크기를 나타냄

        - data sample $x_0$에서 시작할 때, <span style='background-color:#fff5b1'>forward diffusion process</span> $q$, (forward process는 고정된 sequence이기 때문에, $x_0$에서 $x_t$ 바로 구할 수 있음)

            $$q(x_t\vert x_0) = \mathcal{N}(x_t\vert \alpha_t x_0,\ \sigma_t^2\mathbb{I})$$

            Markov 구조에 따라 $s < t$일 때, 

            $$q(x_t|x_s)=\mathcal{N}(x_t \vert \alpha_{t\vert s}x_s,\ \sigma^2_{t\vert s}\mathbb{I})$$

            $$\alpha_{t\vert s} = \frac{\alpha_t}{\alpha_s},\qquad \sigma^2_{t\vert s}=\sigma_t^2-\alpha^2_{t\vert s}\sigma^2_s$$

        - <span style='background-color:#fff5b1'>Denoising diffusion models은 generative models</span> $p(x_0)$로, 위의 과정을 비슷한 Markov 구조를 거꾸로 실행함
            
            $$p(x_0)=\int_z p(x_T)\ \Pi^T_{t=1}\ p(x_{t-1}\vert x_t)$$

            위의 모델과 연관된 evidence lower bound (ELBO)로 이산적인(discrete) time step으로 분해

            $$-log\ p(x_0) \leq \mathbb{KL}(q(x_T\vert x_0)\ \vert\ p(x_T)) + \sum^T_{t=1} \mathbb{E}_{q(x_t\vert x_0)}\mathbb{KL}(q(x_{t-1}\ \vert\ x_t, x_0)\ \vert\ p(x_{t-1}\ \vert\ x_t))$$

            prior $p(x_T)$는 표준 정규 분포로 정해지며, 위 부등식의 첫 번째 항 $\mathbb{KL}(q(x_T\vert x_0)\ \vert\ p(x_T))$은 최종 $SNR(T)$에만 영향을 받기에 고려하지 않아도 됨<br>

            남은 항을 최소화 하기 위해서, $p(x_{t-1}\vert x_t)$를 매개 변수화(parameterize)하기 위해 일반으로 실제 사후 확률(posterior) $q(x_{t-1} \vert x_t, x_0)$를 사용 $\rightarrow$ 하지만 $x_0$는 알 수 없기에, 현재 step $x_t$에 대한 추측값 $x_\theta(x_t,t)$로 대체하여 사용함<br>

            위의 $q(x_{t-1}\ \vert\ x_t, x_0)$와 $p(x_{t-1}\ \vert\ x_t)$가 비슷해야하므로 아래와 같이 정의할 수 있음

            $$\begin{align*}
            p(x_{t-1}\vert x_t) &:= q(x_{t-1}\ \vert\ x_t, x_\theta(x_t,t))\\
            &= \mathcal{N}(x_{t-1}\ \vert\ \mu_\theta(x_t,t),\ \sigma^2_{t\vert t-1}\ \frac{\sigma^2_{t-1}}{\sigma^2_t}\ \mathbb{I})
            \end{align*}$$

            평균값은 아래와 같이 다시 표현할 수 있음 

            $$\mu_\theta(x_t,t) = \frac{\alpha_{t\vert t-1}\ \sigma^2_{t-1}}{\sigma_t^2}\ x_t + \frac{\alpha_{t-1}\ \sigma^2_{t\vert t-1}}{\sigma_t^2}\ x_\theta(x_t,t)$$

        - ELBO를 다 더하는 경우를 간단하게 아래처럼 정리할 수 있음

            $$\sum_{t=1}^T\mathbb{E}_{q(x_t\vert x_0)} \mathbb{KL}(q(x_{t-1}\vert x_t, x_0)\vert p(x_{t-1})) $$
            $$ = \sum_{t=1}^T\mathbb{E}_{\mathcal{N}(\epsilon\vert 0, \mathbb{I})}\frac{1}{2}(SNR(t-1)-SNR(t)) \Vert x_0 - x_\theta(\alpha_t x_0 + \sigma_t\epsilon,t) \Vert^2$$

        - reparameterization을 통해, reconstruction term을 사용하여 denoising objective로 사용

            $$\epsilon_\theta(x_t, t) = (x_t - \alpha_t x_\theta (x_t, t)) / \sigma_t$$

            $$\Vert x_0 - x_\theta(\alpha_t x_0 + \sigma_t \epsilon, t) \Vert^2 
            = \frac{\sigma_t^2}{\alpha_t^2} \Vert \epsilon - \epsilon_\theta(\alpha_t x_0 + \sigma_t \epsilon, t) \Vert^2$$

        - reweighting을 하면 최종 수식으로 정리 가능

            $$L_{DM} = \mathbb{E}_{x, \epsilon \sim \mathcal{N}(0,1), t}[\ \Vert \epsilon - \epsilon_\theta(x_t,t) \Vert^2_2\ ]$$
        <br>

        </div>
        </details>
        
### Generative Modeling of Latent Representations
- $\mathcal{E}, \mathcal{D}$로 구성된 미리 학습된 perceptual compression models을 사용 $\rightarrow$ 효율적이고 작은 차원의 latent space 사용 가능 (고주파수, 인지할 수 없는 세부사항들이 빠짐)<br>

    아래 2가지 이유로, 작은 차원의 latent space가 고차원 pixel space보다 likelihood-based generative model에 더 적합함<br>

    1\) 데이터에서 중요하고 의미가 있는 bit에 집중 가능<br>
    2\)  연산적 측면에서 더 효율적인 낮은 차원에서 학습 <br>

- 제안된 모델이 가진 image-specific inductive biases를 사용하여

많이 압축된 이산적인 latent space를 사용하는 autoregressive, attention-based transformer에 의존한 이전 방법을 사용하지 않음

    

    



 
