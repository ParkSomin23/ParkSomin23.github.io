---
title: "CLAR: Contrastive Learning of Auditory Representations"
date: 2022-06-16 18:44
tag: [Self-Supervised Learning, SSL, Audio]

published: true
toc: true
toc_sticky: false
---
> WORKING ON THIS PAGE

> **Abstract**
> 1. 다양한 data augmentations  
> 2. time-frequency audio feature > raw signals in learned representations
> 3. supervised & contrastive losses(semi-supervised) > self-supervised pre-training       $\rightarrow$ supervised fine-tuning 
> 4. converge faster with significantly better representations

# 1. Introduction
- supervised learning 
    - input signal과 class mapping
    - generalizability limitation
        - expensive to label
        - skewed towards ont partivular damain (e.g. speech, music, etc...)   
- vision self-supervised model SimCLR based model for audio  
<br/>

# 2. Related Works
## 1) Self-Supervised Contrastive Learning
- input pair의 similarity / dissimilarity 학습
- SimCLR이 다른 SSL 모델뿐만 아니라 supervised보다 성능이 좋았음(vision)
- 같은 data의 2개의 augmentated view는 argreement 최대화
- 다른 data와는 contrastive loss 최대화
- NT-Xent: Normalized Temperature-scaled Cross Entropy Loss

    $$
    \mathcal{L}_{CL}=-\sum_{i,j}^Nlog\frac{exp(sim(\mathbf{z}_i, \mathbf{z}_j)/ \tau)}{\sum_{k=1}^{2N}\mathbf{1}_{[k \neq i]} exp(sim(\mathbf{z}_i, \mathbf{z}_j)/ \tau)}
    $$

    - $\mathbf{1}_{[k \neq i]}\in 0,\ 1$ : $k \neq i$일 때만 1 아니면 0
    - $\tau$ : temperature parameter (default 0.5) 
    - $\mathbf{z}$ : encoded representation
    - $N$ : mini-batch size
    - $(i,\ j)$: positive pairs
    - $sim(\mathbf{u}, \mathbf{v})$ : $sim(\mathbf{u}, \mathbf{v}) = \mathbf{u}^T\mathbf{v} / \Vert\mathbf{u}\Vert\Vert\mathbf{v}\Vert$ cosine similarity between two normalized vector $\mathbf{u}$ and $\mathbf{v}$  
    <br/>  

    <p align="center">
    <img src="../assets/images/CLAR/minibatch.jpeg" width="20%">
    </p>  

<br/>

## 2) Supervised Contrastive Learning
- Cross-Entropy Loss이 가장 흔하게 쓰이는 방법
- hyper-parameter, noisy labels에 민감히고, margin도 약함 
- **SupCon**에서 문제를 해결하고자함  

    | NT-Xent | SupCon |
    | :---:   | :---:  |
    | 같은 class의 set와 남은 다른 class와 비교 | 같은 이미지에서 augment한 이미지와 batch 내의 다른 이미지들과 비교|
    | SSL | supervised |
- CLAR에서는 supervised와 self-supervised 방식 힘께 사용
- efficient representation & faster training  
<br/>

# 3. Methods
## 1) Audio Pre-processing
- raw audio signal과 time-frequency audio features로 실험 진행
- 둘 다 16 kHz로 down-sampling 한 후에, 길이가 같아지도록 zero-padding 혹은 오른쪽 넘은 부분 clipping
- **time-frequency audio features**
    - 16ms windows and 8 ms stride STFT magnitude & phase 
    - 128 frequency bins equally spaced on the Mel scale(128 mel filter) 
    - STFT magnitude & mel spectrogram log-power
        $$
        f(S)=10log_{10}\vert S\vert^2
        $$
    - channel 축으로 STFT magnitude, phase, mel spectrogram concat >> $3\times F \times T$
    - multi-domain audio signal(speech, environmental, music, etc) + ResNet 구조 유지
    - GPU 1D convolutional Neural Network로 만듦 >> [nnaudio toolbox](https://github.com/KinWaiCheuk/nnAudio)

## 2) Training/Evaluating Protocol

## 3) Datasets

# 4. CLAR Framework